name: infra-import-plan

on:
  workflow_dispatch:
    inputs:
      apply_imports:
        description: Run terraform import (APPLY=1)
        required: true
        default: true
        type: boolean
      collect_bucket_facts:
        description: Gather S3 bucket diagnostics (policies, lifecycle, encryption)
        required: false
        default: false
        type: boolean
  push:
    branches: [ main ]
    paths:
      - 'infra/terraform/**'
      - 'source/photography/.github/workflows/infra-import-plan.yml'

jobs:
  import_and_plan:
    runs-on: ubuntu-latest

    # All steps run in infra/terraform as requested
    defaults:
      run:
        shell: bash
        working-directory: infra/terraform

    env:
      # Repo secrets and region
      AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      AWS_DEFAULT_REGION: us-west-1
      AWS_REGION: us-west-1
      TF_IN_AUTOMATION: "1"

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.6.6

      - name: Verify or install AWS CLI v2
        run: |
          if ! command -v aws >/dev/null 2>&1; then
            echo "Installing AWS CLI v2"
            curl -sSL "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
            unzip -q awscliv2.zip
            sudo ./aws/install
          fi
          aws --version

      - name: Show caller identity
        run: aws sts get-caller-identity

      - name: Terraform init with S3 backend
        run: terraform init -backend-config=backend.hcl

      - name: Ensure import script is executable
        run: chmod +x ./import_route53_s3.sh

      - name: Import commands (dry run)
        run: ./import_route53_s3.sh

      - name: Execute imports when manual dispatch
        if: github.event_name == 'workflow_dispatch' && (github.event.inputs.apply_imports == true || github.event.inputs.apply_imports == 'true')
        env:
          APPLY: "1"
        run: ./import_route53_s3.sh

      - name: Collect S3 bucket facts
        if: github.event_name == 'workflow_dispatch' && (github.event.inputs.collect_bucket_facts == true || github.event.inputs.collect_bucket_facts == 'true')
        run: |
          set +e
          mkdir -p diagnostics
          echo "Collecting cee artifacts bucket details"
          aws s3api get-bucket-location --bucket cee-artifacts-prod-780997964150-usw1 > diagnostics/artifacts-location.json
          aws s3api get-bucket-versioning --bucket cee-artifacts-prod-780997964150-usw1 > diagnostics/artifacts-versioning.json
          aws s3api get-bucket-encryption --bucket cee-artifacts-prod-780997964150-usw1 > diagnostics/artifacts-encryption.json
          aws s3api get-bucket-lifecycle-configuration --bucket cee-artifacts-prod-780997964150-usw1 > diagnostics/artifacts-lifecycle.json
          aws s3api get-bucket-policy --bucket cee-artifacts-prod-780997964150-usw1 > diagnostics/artifacts-policy.json
          echo "Collecting assets bucket details"
          if aws s3api head-bucket --bucket japanesebirdcookingspaghetti-assets >/dev/null 2>&1; then
            aws s3api get-bucket-location --bucket japanesebirdcookingspaghetti-assets > diagnostics/assets-location.json
            aws s3api get-bucket-versioning --bucket japanesebirdcookingspaghetti-assets > diagnostics/assets-versioning.json
            aws s3api get-bucket-encryption --bucket japanesebirdcookingspaghetti-assets > diagnostics/assets-encryption.json
            aws s3api get-bucket-lifecycle-configuration --bucket japanesebirdcookingspaghetti-assets > diagnostics/assets-lifecycle.json
            aws s3api get-bucket-policy --bucket japanesebirdcookingspaghetti-assets > diagnostics/assets-policy.json
          else
            echo "assets bucket not accessible with current credentials" > diagnostics/assets-unavailable.txt
          fi
          exit 0

      - name: Upload bucket diagnostics
        if: github.event_name == 'workflow_dispatch' && (github.event.inputs.collect_bucket_facts == true || github.event.inputs.collect_bucket_facts == 'true')
        uses: actions/upload-artifact@v4
        with:
          name: s3-bucket-diagnostics
          path: infra/terraform/diagnostics/
          if-no-files-found: warn

      - name: Terraform plan (detailed exit code)
        id: plan
        run: |
          set +e
          terraform plan -detailed-exitcode -no-color -out plan.tfplan
          exit_code=$?
          echo "exit_code=$exit_code" >> "$GITHUB_OUTPUT"
          terraform show -no-color plan.tfplan > plan-full.txt
          # single-line summary
          grep -E "^Plan:" -m1 plan-full.txt > plan.txt || echo "Plan summary unavailable" > plan.txt
          # always continue so we can upload artifacts even if changes exist
          exit 0

      - name: Upload plan artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: terraform-plan
          path: |
            infra/terraform/plan.txt
            infra/terraform/plan-full.txt
            infra/terraform/plan.tfplan
          if-no-files-found: error

      - name: Fail build if plan has changes
        if: steps.plan.outputs.exit_code == '2'
        run: |
          echo "Terraform reported changes. See artifacts for details."
          exit 1
